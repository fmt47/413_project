{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resnet152 model for Covid-19 classification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_time(elapsed):\n",
    "    elapsed_rounded = int(round(elapsed, 2))\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class COVIDDataset(Dataset):\n",
    "    def __init__(self, data_file, transform=None):\n",
    "        self.data = []\n",
    "        self.transform = transform\n",
    "        self.map = {'negative': 0, 'positive': 1}\n",
    "        \n",
    "        with open(data_file, 'r') as f:\n",
    "            folder = os.path.splitext(data_file)[0]\n",
    "            for line in f:\n",
    "                patient_id, filename, label, data_source = line.strip().split(' ')\n",
    "                image_path = os.path.join(folder, filename)\n",
    "                self.data.append((image_path ,self.map[label]))\n",
    "                \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path, label = self.data[index]\n",
    "        image = Image.open(image_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the modified ResNet152 model\n",
    "class ModifiedResNet152(nn.Module):\n",
    "    def __init__(self, num_classes=2, pretrained=True):\n",
    "        super(ModifiedResNet152, self).__init__()\n",
    "        if pretrained:\n",
    "            self.resnet = models.resnet152(weights=models.ResNet152_Weights.DEFAULT)\n",
    "        else:\n",
    "            self.resnet = models.resnet152()\n",
    "        self.resnet.avgpool = nn.AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "        self.resnet.fc = nn.Sequential(\n",
    "            nn.Linear(in_features=2048, out_features=1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_features=1024, out_features=num_classes),\n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "def train(model, train_loader, optimizer, criterion, device, mse=False):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    print(f'Loading # {len(train_loader)} datas')\n",
    "    \n",
    "    with tqdm(train_loader, unit='batch') as tepoch:\n",
    "        for data, target in tepoch:\n",
    "            tepoch.set_description(f\"Training\")\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            # instead of  optimizer.zero_grad(), do it in forloop for more efficiency\n",
    "            for param in model.parameters():\n",
    "                param.grad = None\n",
    "\n",
    "            output = model(data)\n",
    "            if not mse:\n",
    "                loss = criterion(output, target)\n",
    "            else:\n",
    "                target_one_hot = torch.zeros(target.shape[0], 2).to(device)\n",
    "                target_one_hot.scatter_(1, target.unsqueeze(1), 1)\n",
    "                loss = criterion(output, target_one_hot.to(device))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = output.max(1)\n",
    "            total += target.size(0)\n",
    "            correct += predicted.eq(target).sum().item()\n",
    "        \n",
    "    acc = 100.*correct/total\n",
    "    return train_loss, acc\n",
    "\n",
    "def validate(model, val_loader, criterion, device, mse=False):\n",
    "    model.eval()\n",
    "    val_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    false_positive = 0\n",
    "    false_negative = 0\n",
    "    true_positive = 0\n",
    "    true_negative = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        with tqdm(val_loader, unit='batch') as tepoch:\n",
    "            for data, target in tepoch:\n",
    "                tepoch.set_description(f\"Validating\")\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                output = model(data)\n",
    "                if not mse:\n",
    "                    val_loss += criterion(output, target).item()\n",
    "                else:\n",
    "                    target_one_hot = torch.zeros(target.shape[0], 2).to(device)\n",
    "                    target_one_hot.scatter_(1, target.unsqueeze(1), 1)\n",
    "                    val_loss += criterion(output, target_one_hot.to(device))\n",
    "                _, predicted = output.max(1)\n",
    "                total += target.size(0)\n",
    "                false_positive += ((predicted == 1) & (target == 0)).sum().item()\n",
    "                false_negative += ((predicted == 0) & (target == 1)).sum().item()\n",
    "                true_negative += ((predicted == 0) & (target == 0)).sum().item()\n",
    "                true_positive += ((predicted == 1) & (target == 1)).sum().item()\n",
    "    correct = true_positive + true_negative\n",
    "    sensitivity = true_positive / (true_positive + false_negative)\n",
    "    specificity = true_negative / (true_negative + false_positive)\n",
    "    f1_score = 2 * true_positive / (2 * true_positive + false_positive + false_negative)\n",
    "    print(f'Validation loss: {val_loss:.4f}, Accuracy: {correct}/{total} ({100.*correct/total:.2f}%), Sensitivity: {sensitivity:.2f}, Specificity: {specificity:.2f}, F1 score: {f1_score:.2f}')\n",
    "    acc = 100.*correct/total\n",
    "    return val_loss, acc, sensitivity, specificity, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_resnet(model, dataset, lr, epochs, batch_size, factor, patience, criterion, device, pretrain, state_for='unprovided', mse=False):\n",
    "    \"\"\"Train the model on the dataset and return the best accuracy\n",
    "    \n",
    "    Args:\n",
    "        model: the model to train\n",
    "        dataset: the dataset to train on\n",
    "        lr: learning rate\n",
    "        epochs: number of epochs to train for\n",
    "        batch_size: batch size\n",
    "        factor: factor for ReduceLROnPlateau\n",
    "        patience: patience for ReduceLROnPlateau\n",
    "        criterion: loss function\n",
    "        device: device to train on (cuda or cpu)\n",
    "        \n",
    "    Returns:\n",
    "        best_acc: best accuracy achieved\n",
    "    \"\"\"\n",
    "    PRETRAIN = 'finetune' if pretrain else 'wo_pretrain'\n",
    "    print(f\"Using device: {device}\")\n",
    "    # get size of dataset\n",
    "    dataset_size = len(dataset)\n",
    "    print(f\"Dataset size: {dataset_size}\")\n",
    "    # split dataset into train and validation sets\n",
    "    train_size = int(0.8 * dataset_size)\n",
    "    val_size = dataset_size - train_size\n",
    "    train_dataset, val_dataset = data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size,\n",
    "                            shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size,\n",
    "                            shuffle=False)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=factor, patience=patience, verbose=True)\n",
    "    # record training and validation losses and accuracies\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_accs = []\n",
    "    val_accs = []\n",
    "    best_acc = 0\n",
    "    best_epoch = 0\n",
    "    model_state_path = \"\"\n",
    "\n",
    "    start = time.time()\n",
    "    print(f\"Began training for {epochs} epochs\")\n",
    "    for epoch in range(epochs):\n",
    "        print(f'Training (Epoch {epoch + 1})')\n",
    "        torch.cuda.empty_cache()\n",
    "        t0 = time.time()\n",
    "        train_loss, train_acc = train(model, train_loader, optimizer, criterion, device, mse)\n",
    "        print(\"  * Training epoch took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "        t0 = time.time()\n",
    "        val_loss, val_acc, val_sen, val_spec, val_f1 = validate(model, val_loader, criterion, device, mse)\n",
    "        print(\"  * Validation took: {:}\".format(format_time(time.time() - t0)))\n",
    "\n",
    "        # record training and validation losses and accuracies\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}, Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.3f}\\nVal Sensitivity: {val_sen:.3f}, Val Specificity: {val_spec:.3f}, Val F1 score: {val_f1:.3f}')\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_epoch = epoch + 1\n",
    "            model_state_path = f'{state_for}_{PRETRAIN}_resnet152.pt'\n",
    "            torch.save(model.state_dict(), model_state_path)\n",
    "    \n",
    "    print(\"Training complete in {}\".format(format_time(time.time() - start)))\n",
    "    print(\"Best validation accuracy: {:.2f}% -- Acquired with epoch {}\".format(best_acc, best_epoch))\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, model_state_path"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Begin Training process for RESNET152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up hyperparameters for the model\n",
    "# Set up hyperparameters and data loaders\n",
    "# TUNABLE:\n",
    "lr = 2e-4\n",
    "# TUNABLE:\n",
    "epochs = 10\n",
    "# TUNABLE: original 64\n",
    "batch_size = 16\n",
    "# TUNABLE:\n",
    "factor = 0.7\n",
    "# TUNABLE:\n",
    "patience = 5\n",
    "# set the model with pretrained weight or not\n",
    "pretrain = True \n",
    "\n",
    "num_classes = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# # Define the transformations to be applied to the data\n",
    "target_size = 224\n",
    "transform = transforms.Compose([\n",
    "        transforms.Grayscale(num_output_channels=3),\n",
    "        transforms.Resize(target_size),\n",
    "        transforms.CenterCrop(target_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "# create COVIDDataset object\n",
    "# TUNABLE: --> can try different datasets\n",
    "dataset = COVIDDataset('train.txt', transform=transform)\n",
    "\n",
    "# Define the model, loss function\n",
    "model = ModifiedResNet152(num_classes, pretrained=pretrain).to(device) # pretrained=True\n",
    "\n",
    "# TUNABLE:\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "state_for = 'ADAM+CE'\n",
    "\n",
    "# criterion = nn.functional.mse_loss\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# state_for = 'ADAM+MSE'\n",
    "\n",
    "# criterion = nn.NLLLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# state_for = 'ADAM+NLL'\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9)\n",
    "# state_for = 'SGD'\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.RMSprop(model.parameters(), lr=lr)\n",
    "# state_for = 'RMSPROP'\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.Adadelta(model.parameters(), lr=1.0, rho=0.9, eps=1e-06, weight_decay=0)\n",
    "# state_for = 'ADADelta'\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "# state_for = 'AdamW'\n",
    "\n",
    "\n",
    "\n",
    "# # Use the pretrained Resnet152. Load the trained ResNet152 model\n",
    "# model = models.resnet152(weights=models.ResNet152_Weights.DEFAULT)\n",
    "# model.fc = torch.nn.Sequential(\n",
    "#     torch.nn.Linear(2048, 1024),\n",
    "#     torch.nn.ReLU(),\n",
    "#     # torch.nn.Linear(1024, 2),\n",
    "#     torch.nn.LogSoftmax(dim=1)\n",
    "# )\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# model.eval()\n",
    "\n",
    "# # Initialize an empty tensor to store the features for all images\n",
    "# all_features = torch.empty(len(dataset), 1024)\n",
    "\n",
    "# # Pass each batch of images through the model to obtain the features\n",
    "# with torch.no_grad():\n",
    "#     start_index = 0\n",
    "#     for images, _ in tqdm(train_loader):\n",
    "#         batch_size = images.shape[0]\n",
    "#         features = model(images)\n",
    "#         all_features[start_index:start_index+batch_size,:] = features\n",
    "#         start_index += batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Dataset size: 29986\n",
      "Began training for 10 epochs\n",
      "Training (Epoch 1)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [17:33<00:00,  1.42batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:17:33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [03:09<00:00,  1.98batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 587.3041, Accuracy: 5902/5998.0 (98.40%), Sensitivity: 0.99, Specificity: 0.98, F1 score: 0.99\n",
      "  * Validation took: 0:03:09\n",
      "Epoch 1, Train Loss: 2357.7884, Train Acc: 97.13, Val Loss: 587.3041, Val Acc: 98.399\n",
      "Val Sensitivity: 0.991, Val Specificity: 0.976, Val F1 score: 0.985\n",
      "Training (Epoch 2)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [11:05<00:00,  2.26batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:11:05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [02:06<00:00,  2.97batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 587.6389, Accuracy: 5890/5998.0 (98.20%), Sensitivity: 0.98, Specificity: 0.98, F1 score: 0.98\n",
      "  * Validation took: 0:02:06\n",
      "Epoch 2, Train Loss: 2350.0967, Train Acc: 98.30, Val Loss: 587.6389, Val Acc: 98.199\n",
      "Val Sensitivity: 0.984, Val Specificity: 0.980, Val F1 score: 0.983\n",
      "Training (Epoch 3)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [10:40<00:00,  2.34batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:10:40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [01:29<00:00,  4.17batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 587.2017, Accuracy: 5904/5998.0 (98.43%), Sensitivity: 0.99, Specificity: 0.97, F1 score: 0.99\n",
      "  * Validation took: 0:01:29\n",
      "Epoch 3, Train Loss: 2347.1892, Train Acc: 98.77, Val Loss: 587.2017, Val Acc: 98.433\n",
      "Val Sensitivity: 0.993, Val Specificity: 0.975, Val F1 score: 0.985\n",
      "Training (Epoch 4)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [08:55<00:00,  2.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:08:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [01:30<00:00,  4.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 589.6378, Accuracy: 5801/5998.0 (96.72%), Sensitivity: 0.97, Specificity: 0.97, F1 score: 0.97\n",
      "  * Validation took: 0:01:30\n",
      "Epoch 4, Train Loss: 2346.3825, Train Acc: 98.88, Val Loss: 589.6378, Val Acc: 96.716\n",
      "Val Sensitivity: 0.967, Val Specificity: 0.967, Val F1 score: 0.969\n",
      "Training (Epoch 5)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [08:58<00:00,  2.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:08:58\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [01:31<00:00,  4.11batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 587.0174, Accuracy: 5910/5998.0 (98.53%), Sensitivity: 0.98, Specificity: 0.99, F1 score: 0.99\n",
      "  * Validation took: 0:01:31\n",
      "Epoch 5, Train Loss: 2345.0624, Train Acc: 99.11, Val Loss: 587.0174, Val Acc: 98.533\n",
      "Val Sensitivity: 0.983, Val Specificity: 0.988, Val F1 score: 0.986\n",
      "Training (Epoch 6)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [09:00<00:00,  2.78batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:09:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [01:30<00:00,  4.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 587.6156, Accuracy: 5878/5998.0 (98.00%), Sensitivity: 1.00, Specificity: 0.96, F1 score: 0.98\n",
      "  * Validation took: 0:01:30\n",
      "Epoch 6, Train Loss: 2344.4209, Train Acc: 99.18, Val Loss: 587.6156, Val Acc: 97.999\n",
      "Val Sensitivity: 0.996, Val Specificity: 0.961, Val F1 score: 0.982\n",
      "Training (Epoch 7)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [09:00<00:00,  2.77batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:09:00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [01:32<00:00,  4.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 587.9381, Accuracy: 5863/5998.0 (97.75%), Sensitivity: 0.98, Specificity: 0.98, F1 score: 0.98\n",
      "  * Validation took: 0:01:32\n",
      "Epoch 7, Train Loss: 2343.1419, Train Acc: 99.46, Val Loss: 587.9381, Val Acc: 97.749\n",
      "Val Sensitivity: 0.975, Val Specificity: 0.980, Val F1 score: 0.979\n",
      "Training (Epoch 8)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [08:55<00:00,  2.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:08:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [01:30<00:00,  4.14batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 586.6254, Accuracy: 5934/5998.0 (98.93%), Sensitivity: 0.99, Specificity: 0.99, F1 score: 0.99\n",
      "  * Validation took: 0:01:30\n",
      "Epoch 8, Train Loss: 2342.8748, Train Acc: 99.47, Val Loss: 586.6254, Val Acc: 98.933\n",
      "Val Sensitivity: 0.988, Val Specificity: 0.991, Val F1 score: 0.990\n",
      "Training (Epoch 9)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [08:55<00:00,  2.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:08:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [01:30<00:00,  4.16batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 586.8544, Accuracy: 5915/5998.0 (98.62%), Sensitivity: 0.99, Specificity: 0.98, F1 score: 0.99\n",
      "  * Validation took: 0:01:30\n",
      "Epoch 9, Train Loss: 2342.2212, Train Acc: 99.60, Val Loss: 586.8544, Val Acc: 98.616\n",
      "Val Sensitivity: 0.995, Val Specificity: 0.976, Val F1 score: 0.987\n",
      "Training (Epoch 10)\n",
      "Loading # 1500 datas\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 1500/1500 [08:55<00:00,  2.80batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  * Training epoch took: 0:08:55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 375/375 [01:30<00:00,  4.15batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 586.6297, Accuracy: 5926/5998.0 (98.80%), Sensitivity: 0.99, Specificity: 0.99, F1 score: 0.99\n",
      "  * Validation took: 0:01:30\n",
      "Epoch 10, Train Loss: 2341.8239, Train Acc: 99.66, Val Loss: 586.6297, Val Acc: 98.800\n",
      "Val Sensitivity: 0.987, Val Specificity: 0.989, Val F1 score: 0.989\n",
      "Training complete in 1:59:24\n",
      "Best validation accuracy: 98.93% -- Acquired with epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_losses, val_losses, train_accs, val_accs, model_state_path = train_resnet(model, dataset, lr, epochs, batch_size, factor, patience, criterion, device, pretrain, state_for)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the loss and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m\"\u001b[39m\u001b[39mLoss (Original ResNet152)\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      9\u001b[0m plt\u001b[39m.\u001b[39mplot(train_losses, label\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mTraining loss\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m---> 10\u001b[0m plt\u001b[39m.\u001b[39;49mplot(val_losses, label\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mValidation loss\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m     11\u001b[0m plt\u001b[39m.\u001b[39mlegend()\n\u001b[0;32m     12\u001b[0m plt\u001b[39m.\u001b[39msubplot(\u001b[39m1\u001b[39m, \u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m)\n",
      "File \u001b[1;32md:\\git repo\\413_project\\csc413proj_venv\\lib\\site-packages\\matplotlib\\pyplot.py:2812\u001b[0m, in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2810\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[39m.\u001b[39mplot)\n\u001b[0;32m   2811\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mplot\u001b[39m(\u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, scaley\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, data\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m-> 2812\u001b[0m     \u001b[39mreturn\u001b[39;00m gca()\u001b[39m.\u001b[39mplot(\n\u001b[0;32m   2813\u001b[0m         \u001b[39m*\u001b[39margs, scalex\u001b[39m=\u001b[39mscalex, scaley\u001b[39m=\u001b[39mscaley,\n\u001b[0;32m   2814\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m({\u001b[39m\"\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m\"\u001b[39m: data} \u001b[39mif\u001b[39;00m data \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m {}), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\git repo\\413_project\\csc413proj_venv\\lib\\site-packages\\matplotlib\\axes\\_axes.py:1688\u001b[0m, in \u001b[0;36mAxes.plot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1445\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1446\u001b[0m \u001b[39mPlot y versus x as lines and/or markers.\u001b[39;00m\n\u001b[0;32m   1447\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1685\u001b[0m \u001b[39m(``'green'``) or hex strings (``'#008000'``).\u001b[39;00m\n\u001b[0;32m   1686\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   1687\u001b[0m kwargs \u001b[39m=\u001b[39m cbook\u001b[39m.\u001b[39mnormalize_kwargs(kwargs, mlines\u001b[39m.\u001b[39mLine2D)\n\u001b[1;32m-> 1688\u001b[0m lines \u001b[39m=\u001b[39m [\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_lines(\u001b[39m*\u001b[39margs, data\u001b[39m=\u001b[39mdata, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)]\n\u001b[0;32m   1689\u001b[0m \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m lines:\n\u001b[0;32m   1690\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_line(line)\n",
      "File \u001b[1;32md:\\git repo\\413_project\\csc413proj_venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:311\u001b[0m, in \u001b[0;36m_process_plot_var_args.__call__\u001b[1;34m(self, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m     this \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m],\n\u001b[0;32m    310\u001b[0m     args \u001b[39m=\u001b[39m args[\u001b[39m1\u001b[39m:]\n\u001b[1;32m--> 311\u001b[0m \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_plot_args(\n\u001b[0;32m    312\u001b[0m     this, kwargs, ambiguous_fmt_datakey\u001b[39m=\u001b[39;49mambiguous_fmt_datakey)\n",
      "File \u001b[1;32md:\\git repo\\413_project\\csc413proj_venv\\lib\\site-packages\\matplotlib\\axes\\_base.py:496\u001b[0m, in \u001b[0;36m_process_plot_var_args._plot_args\u001b[1;34m(self, tup, kwargs, return_kwargs, ambiguous_fmt_datakey)\u001b[0m\n\u001b[0;32m    494\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(xy[\u001b[39m1\u001b[39m])\n\u001b[0;32m    495\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     x, y \u001b[39m=\u001b[39m index_of(xy[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n\u001b[0;32m    498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mxaxis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    499\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes\u001b[39m.\u001b[39mxaxis\u001b[39m.\u001b[39mupdate_units(x)\n",
      "File \u001b[1;32md:\\git repo\\413_project\\csc413proj_venv\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1656\u001b[0m, in \u001b[0;36mindex_of\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m   1654\u001b[0m     \u001b[39mpass\u001b[39;00m\n\u001b[0;32m   1655\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1656\u001b[0m     y \u001b[39m=\u001b[39m _check_1d(y)\n\u001b[0;32m   1657\u001b[0m \u001b[39mexcept\u001b[39;00m (np\u001b[39m.\u001b[39mVisibleDeprecationWarning, \u001b[39mValueError\u001b[39;00m):\n\u001b[0;32m   1658\u001b[0m     \u001b[39m# NumPy 1.19 will warn on ragged input, and we can't actually use it.\u001b[39;00m\n\u001b[0;32m   1659\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "File \u001b[1;32md:\\git repo\\413_project\\csc413proj_venv\\lib\\site-packages\\matplotlib\\cbook\\__init__.py:1348\u001b[0m, in \u001b[0;36m_check_1d\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m   1342\u001b[0m \u001b[39m# plot requires `shape` and `ndim`.  If passed an\u001b[39;00m\n\u001b[0;32m   1343\u001b[0m \u001b[39m# object that doesn't provide them, then force to numpy array.\u001b[39;00m\n\u001b[0;32m   1344\u001b[0m \u001b[39m# Note this will strip unit information.\u001b[39;00m\n\u001b[0;32m   1345\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1346\u001b[0m         \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mor\u001b[39;00m\n\u001b[0;32m   1347\u001b[0m         \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[1;32m-> 1348\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49matleast_1d(x)\n\u001b[0;32m   1349\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1350\u001b[0m     \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32md:\\git repo\\413_project\\csc413proj_venv\\lib\\site-packages\\numpy\\core\\shape_base.py:65\u001b[0m, in \u001b[0;36matleast_1d\u001b[1;34m(*arys)\u001b[0m\n\u001b[0;32m     63\u001b[0m res \u001b[39m=\u001b[39m []\n\u001b[0;32m     64\u001b[0m \u001b[39mfor\u001b[39;00m ary \u001b[39min\u001b[39;00m arys:\n\u001b[1;32m---> 65\u001b[0m     ary \u001b[39m=\u001b[39m asanyarray(ary)\n\u001b[0;32m     66\u001b[0m     \u001b[39mif\u001b[39;00m ary\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     67\u001b[0m         result \u001b[39m=\u001b[39m ary\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32md:\\git repo\\413_project\\csc413proj_venv\\lib\\site-packages\\torch\\_tensor.py:970\u001b[0m, in \u001b[0;36mTensor.__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    968\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m__array__, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    969\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 970\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnumpy()\n\u001b[0;32m    971\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    972\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mastype(dtype, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot training and validation losses and accuracies\n",
    "now = datetime.datetime.now()\n",
    "now = now.strftime(\"%Y-%m-%d_%H%M%S\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(\"Loss (Original ResNet152)\")\n",
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(val_losses, label='Validation loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(\"Accuracy (Original ResNet152)\")\n",
    "plt.plot(train_accs, label='Training accuracy')\n",
    "plt.plot(val_accs, label='Validation accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('./resnet_plots/' + f'{state_for}_loss_resnet152_{now}.png')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the resnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model ADAM+MSE_finetune_resnet152.pt loaded\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validating: 100%|██████████| 25/25 [00:40<00:00,  1.61s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 39.3618, Accuracy: 387/400.0 (96.75%), Sensitivity: 0.94, Specificity: 1.00, F1 score: 0.97\n",
      "Test loss: 39.3618, Test accuracy: 96.750%, Test sensitivity: 0.935%, Test specificity: 1.000%, Test F1 score: 0.966%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "test_dataset = COVIDDataset('test.txt', transform=transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "model_path = model_state_path\n",
    "# model_path = 'RMSPROP_finetune_resnet152.pt'\n",
    "\n",
    "# load best model\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "print(f'Model {model_path} loaded')\n",
    "# evaluate model on test set\n",
    "test_loss, test_acc, test_sen, test_spec, test_f1 = validate(model, test_loader, criterion, device)\n",
    "print(f'Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.3f}%, Test sensitivity: {test_sen:.3f}%, Test specificity: {test_spec:.3f}%, Test F1 score: {test_f1:.3f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csc413proj_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
